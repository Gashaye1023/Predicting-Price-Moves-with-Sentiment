{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acddb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load historical stock data\n",
    "stock_data = {}\n",
    "data_folder = '../yfinance_data'\n",
    "\n",
    "# Load each historical data file\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith('_historical_data.csv'):\n",
    "        ticker = file.split('_')[0]  # Extract ticker symbol\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        stock_data[ticker] = pd.read_csv(file_path)\n",
    "        stock_data[ticker]['Date'] = pd.to_datetime(stock_data[ticker]['Date'])\n",
    "\n",
    "fns_pid_data = pd.read_csv(os.path.join(data_folder, 'raw_analyst_ratings.csv'))\n",
    "\n",
    "# Convert the 'date' column to datetime\n",
    "fns_pid_data['date'] = pd.to_datetime(fns_pid_data['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0460a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.407328e+06\n",
      "mean     7.312051e+01\n",
      "std      4.073531e+01\n",
      "min      3.000000e+00\n",
      "25%      4.700000e+01\n",
      "50%      6.400000e+01\n",
      "75%      8.700000e+01\n",
      "max      5.120000e+02\n",
      "Name: headline_length, dtype: float64\n",
      "publisher\n",
      "Paul Quintaro        228373\n",
      "Lisa Levin           186979\n",
      "Benzinga Newsdesk    150484\n",
      "Charles Gross         96732\n",
      "Monica Gerson         82380\n",
      "                      ...  \n",
      "Matthew Ely               1\n",
      "Frank Ochoa               1\n",
      "Jeremie Capron            1\n",
      "Marvin Dumont             1\n",
      "Igor Gonta                1\n",
      "Name: count, Length: 1034, dtype: int64\n",
      "date\n",
      "2011-04-27      1\n",
      "2011-04-28      2\n",
      "2011-04-29      2\n",
      "2011-04-30      1\n",
      "2011-05-01      1\n",
      "             ... \n",
      "2020-06-07     25\n",
      "2020-06-08    765\n",
      "2020-06-09    804\n",
      "2020-06-10    806\n",
      "2020-06-11    544\n",
      "Name: count, Length: 2528, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics for headline lengths\n",
    "fns_pid_data['headline_length'] = fns_pid_data['headline'].str.len()\n",
    "print(fns_pid_data['headline_length'].describe())\n",
    "\n",
    "# Count articles per publisher\n",
    "articles_per_publisher = fns_pid_data['publisher'].value_counts()\n",
    "print(articles_per_publisher)\n",
    "\n",
    "# Analyze publication dates\n",
    "fns_pid_data['date'] = pd.to_datetime(fns_pid_data['date'])\n",
    "publication_trends = fns_pid_data['date'].dt.date.value_counts()\n",
    "print(publication_trends.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e059a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('vs', np.int64(162099)), ('stocks', np.int64(161776)), ('est', np.int64(140604)), ('eps', np.int64(128897)), ('market', np.int64(120558)), ('shares', np.int64(114313)), ('reports', np.int64(108710)), ('update', np.int64(91723)), ('earnings', np.int64(87399)), ('sales', np.int64(79645))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(fns_pid_data['headline'])\n",
    "common_words = X.sum(axis=0).A1\n",
    "words = vectorizer.get_feature_names_out()\n",
    "word_counts = dict(zip(words, common_words))\n",
    "sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_words[:10])  # Top 10 common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacff649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "for ticker in stock_data:\n",
    "    if 'headline' not in stock_data[ticker].columns:\n",
    "        stock_data[ticker]['headline'] = ''  # Fill with empty string if missing\n",
    "# Calculate the sentiment for each stock's headlines\n",
    "for ticker in stock_data:\n",
    "    stock_data[ticker]['Sentiment'] = stock_data[ticker]['headline'].apply(lambda x: TextBlob(x).sentiment.polarity )\n",
    "\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity  # Value between -1 (negative) and 1 (positive)\n",
    "\n",
    "# Apply sentiment analysis\n",
    "fns_pid_data['Sentiment'] = fns_pid_data['headline'].apply(get_sentiment)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
